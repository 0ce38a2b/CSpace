Abstract
The slowdown of Moore몶s law and the existence of the "von Neumann bottleneck" makes the electronic-based computing system under von Neumann's architecture unable to meet the fast-growing demand for artificial intelligence computing. However, all-optical diffractive neural networks provide a possible solution to this challenge. It can outperform conventional silicon-based electronic neural networks due to the significantly higher speed of propagation of optical signals(\approx{10}^8m\cdot s^{-1}) as compared to those of electrical signals(\approx{10}^5m\cdot s^{-1}), its parallelism in nature and low power consumption. Integrated diffractive deep neural network (ID^2NN) uses an on-chip fully-passive photonic approach to perform the functionality of neural networks (matrix-vector operation) and can be fabricated using the CMOS process, which is technologically more amenable to implementing an artificial intelligence processor. In this thesis, we present the detailed design framework of the integrated diffractive deep neural networks and corresponding silicon-on-insulator integration implementation. The performance of our proposed  ID^2NN is evaluated by solving image classification problems using the MNIST and Fashion-MNIST datasets. 
Keywords:  integrated photonic diffractive deep neural network, optical computing, on-chip computing, image classification












Integrated Photonic Image Classifier using Deep Diffractive
Neural Networks
Introduction
모모Deep learning[1] is a fast-growing field with many use cases and applications in computer vision[2], speech recognition[3], robotic systems[4], etc. However, the real-world engineering applications of deep neural networks(DNN) have been limited due to the inference time and increased computational power associated with these networks.[5] Although much of the recent advances in deep learning have been enabled by electronic-based hardware, its optical implementation has great significance because of the intrinsic parallelism and light-speed computing with low power consumption.[6, 7] As we move into the future, big challenges appear in making computing chips faster and keeping pace with Moore's law.[8] For instance, as autonomous vehicles rely on cameras and artificial intelligence image processing to make decisions at high speed, conventional digital processors show significant incompetence, whereas the optic-driven computing method is poised to address the challenges. [9]
모모An integrated photonic diffractive deep neural network(ID^2NN) is one of the most exciting cross-discipline fields of artificial intelligence and optical computing, combining deep learning with the power of light-speed processing on an integrated platform. With remarkable progress and advancement in silicon photonic integrated circuits over the last few decades, ID^2NN hold the promise of on-chip miniaturisation and high-speed performance with low power consumption for artificial intelligence computing.
1.1 Background and Research Significance
모모Artificial Neural Networks (ANN)[10, 11] can be trained and inferenced on computing systems that are based on integrated circuit chips (IC) made of silicon. These networks can operate on central processing units (CPU), graphics processing units (GPU), field-programmable gate arrays (FPGA), and application-specific integrated circuits (ASIC). However, regardless of the type of IC chip used, the Von Neumann architecture employed in these systems separates the program space from the data space, causing data to be transmitted serially between the two. Thus, the speed of Computation under Von Neumann's architecture is limited by the efficiencies of data transfer and the speed of processing(data computation).[12, 13] Also, these electronic circuits operate based on millions of transistors that induce latency and generate heat. Those lead to a significant amount of data transfer between the memory and computation unit, reducing the speed of individual computations and increasing energy consumption, resulting in the well-known "Von Neumann bottleneck" problem.
모모On the one hand, this bottleneck limits the growth of computing power in ANNs [14C17], while on the other hand, the demand for computing power by ANNs continues to grow rapidly[18C21]. A recent analysis conducted by OpenAI has revealed that the amount of computational resources utilized in the largest artificial intelligence (AI) training and inference processes has been growing exponentially, with a doubling time of 3.4 months. AI computing is significantly faster than the 2-year doubling period observed in Moore's Law[22, 23], as shown in Figure 1-1. From 2012 to the present, this metric has increased by over 300,000 times, much higher than the 7 times growth that would have been achieved with a 2-year doubling period. Given that advancements in computational resources have been a crucial factor in the progress of artificial intelligence, it is important to be prepared for the possibilities of systems that will greatly surpass current capabilities as long as this trend continues.

Figure 11: The growing demand for artificial intelligence computing[source: OpenAI]

모모Photonics technology involves the use of photons as a means for transmitting and processing information. It is considered to be the ideal medium for information transfer and processing. In recent years, researchers have leveraged the power of photonics to accelerate the inference of neural networks.[24C26] The main ones are photonic chips-based and optical diffractive neural networks[27]. The former uses optical interference unit to process meshes of light, and the latter performs analogue computing through wave propagation. Diffractive deep neural network(D^2NN) focus on the paradigm that uses light waves as the computing medium to perform the functionality of neural networks. The interference pattern of waves will determine the result, allowing instantaneous computation. In other words, the signals are processed in the optical domain while in motion. Thus, computing at the speed of light can be achieved, and notably, it will produce massive performance and efficiency gains. It has now become one of the most promising solutions for breaking through the Von Neumann bottleneck and the technical barriers of high time delay and energy consumption of traditional electrical artificial neural networks in the Post-Moore era.
모모With integrated photonic circuits, light can be confined and propagated through structures on a plate to perform computing.[28C31] It is a scalable and mature technology available that can do hybrid integration of devices and material technologies. [39]A diffractive deep neural network can be integrated physically on a standard silicon-on-insulator (SOI) substrate that enables the reduction of size, power consumption and cost per function. This thesis is dedicated to developing an integrated deep diffractive neural network(ID^2NN) that will provide an alternative machine learning architecture for on-chip optical computing that may address the needs of artificial intelligence systems. 
1.2  Thesis Contributions 
모모In order to overcome the limitations existing in neuron network inference under Von Neumann architecture and to leverage the advantages of light in terms of speed, parallelism, and energy efficiency, this thesis has been conducted based on the analysis of recent research in the field of optical diffractive neural networks. We have proposed a highly integrated multi-layer diffractive deep neural network architecture, designed corresponding inference and training framework, and validated the system's feasibility through simulation experiments. The main contributions of this thesis are as follows:
 We have proposed an all-optical integrated neural network computing architecture based on the principle of diffraction. The network's structure can perform matrix-vector multiplication (dot product) and is designed using the 2D Rayleigh-Sommerfeld diffraction integral, resulting in high integration.
 We have explored the fully connected topology of the integrated diffractive deep neural network. By conducting a quantitative analysis of the restrictive relationships among the physical parameters within the system, we have derived formulas that enable quantitative design and flexible regulation of system parameters. It is worth noting that the design of ID^2NN should be based on the fully connected architecture.
 We have designed and implemented the inference model and training framework for ID^2NN. The inference model consists of data preprocessing, an input layer (data loading), multiple diffractive layers, and output detectors. The training algorithm is based on the error backpropagation method, which utilizes complex-number derivatives.
 By applying the technique of multi-process programming, we significantly sped up the computation involved in field propagation and achieved a
120-time reduction of computation time. This improves the computational speed for both inference and training.
 We have conducted simulations and analysis of ID^2NN in both Python environment and Lumerical FDTD. The result demonstrated that a 5-layer  ID^2NN can achieve a 91.6% classification accuracy on the MNIST dataset. 
1.3 Thesis  Outline 
모모This thesis is organized into seven chapters, as detailed below: Chapter 1 provides the background for the research topic, discussing the growing demand and challenges associated with artificial intelligence computing and the advantages of photonic computing technology. This chapter highlights the motivation and significance of this research and presents an overview of the thesis's primary contributions. Chapter 2 comprehensively reviews recent advancements and the current research status of optical diffractive neural networks. It delves into an analysis of existing optical diffractive neural network models, emphasizing their design principles, implementation techniques, and performance limitations, thus laying the foundation for the development of integrated optical neural networks. Chapter 3 introduces the fundamental building blocks of the integrated diffractive deep neural network: the computational method of wave propagation and the complex-valued neural network. Chapter 4 presents the design methodology based on the Rayleigh-Sommerfeld diffraction integral and the fully connected architecture for constructing and training a multi-layer integrated diffractive deep neural network. Chapter 5 analyzes the impact of different types of loss functions and the number of diffraction layers on the system performance, followed by computer-based simulations in Chapter 6, where analysis of model-system mismatch (refer as error analysis) is also included. In Chapter 7, we conclude the thesis and offer an outlook for future research directions.

Figure 12: Structure of this thesis
 Literature Review
모모By leveraging the photonic technology as the driving computing force for artificial neural networks, the Diffractive Deep Neural Network, D^2NN , also known as the Optical Diffraction Neural Network (ODNN), employs light as its medium for information transmission. It uses the diffraction principle for propagation and directly processes information carried in an optical field at the physical level with micro/nano optical components. These components encompass diffractive optical elements (DOEs), metasurfaces, and spatial light modulators (SLMs). [32C34]The output field conveys the result of task-specific computing and serves as a basis for assessing the effectiveness and versatility of this innovative approach. Here, we point out that compared with D^2NN realised in free space, the integrated diffractive neural network  we are going to develop in this thesis is smaller in size, which also has excellent potential application value in other machine learning models(i.e. unsurprised learning, reinforcement learning)[35, 36]. In order to effectively integrate the optical diffractive neural network into a chip, it is necessary to understand their non-integrated implementation in free space.
모모This chapter first gives an overview of diffractive deep neural networks and then reviews the research status of diffractive deep neural networks in optical computing, especially for computer vision tasks such as image classification. The problems associated with narrowing down the current applications of D^2NN are also discussed at the end of the chapter.
2.1 Overview of  Diffractive Deep Neural Networks
모모The all-optical diffractive deep neural network was first proposed by Lin Xing in 2018[27], which focused on the application of image classification. The diffractive deep neural network comprises multiple diffractive layers, where each diffractive layer is equated to a hidden layer, and each cell on the diffractive layer is analogous to a single neuron in a traditional neural network. The input layer encodes the image into the amplitude or phase channel of the incident field, while the output plane measures the intensity of the field. When a coherent light beam enters the first layer of the network, each point on a specific layer functions as a secondary wave source, according to Huygens' principle[37]. Its amplitude and phase are determined by the product of the input wave and the complex-valued transmission coefficient at that location.  A neuron in the diffractive neural network is thus accordingly linked to other neurons in the subsequent layer, as illustrated in Figure 11.
모모
모모Figure 21: Illustration of diffractive deep neural network
Figure 22: Framework of diffractive deep neural network Spatial architecture of diffractive deep neural network(b) Area Division of the Detection Plane(c) When the input image is the digit 2, the region corresponding to the digit 2 has the maximum energy level모모The diffractive deep neural network modulates the optical field using multiple physical layers of diffractive optical elements. Each layer consists of micro/nano-structural units leading to specific phase distributions. However, deriving these particular phase distributions necessitates a computer-based deep learning framework(i.e. Pytorch, Tensorflow).[38, 39] Within this framework, the phase distribution in each layer is progressively optimized through training algorithms. This process ensures that the optical output field exhibits a specific light intensity distribution, enabling it to perform the intended task. Once trained, the diffractive deep neural network can be fabricated by mapping the well-trained phase distributions into the heights of the corresponding micro/nanostructures. In subsequent uses, the entire system executes the application-specific computing task at the speed of light, excluding the initial light source and back-end detection equipment. The computing process operates without electricity, significantly reducing running time and energy consumption.
모
Figure 23: Modulation process of diffractive deep neural network with four examples2.2 Research Status of Diffractive Deep Neural Networks
모모In recent studies, researchers have built upon the D^2NN framework to investigate the range of wavelengths which can be applied to optical diffractive neural networks and their performance on different tasks. The terahertz band is the distinctive frequency range where optical diffraction neural networks were first employed. Once the optical diffractive neural network has been trained, it can be manufactured using nanofabrication technologies. The difficulty of fabrication depends on the feature size of the micro-structure unit cell(the neuron in the optical system), which is generally regulated by Equation (4-4). As the size of the unit cell increases, the fabrication process becomes more accessible.  Researchers have broadened the light source for the diffractive neural network to visible and infrared wavelengths. The former makes an effort to reduce the setup complexity of the optical system, while the latter steps into the miniaturisation of the system. The table below summarizes the design parameters of the D^2NN system at different operating wavelengths.
Table 21: System design parameters of diffractive deep neural networks at different wavelengths

Source and Publication YearThe wavelength of the Light Source, \lambdaNeuron Feature Size, \mathrm{\Delta d}Cui T J et al., Nature Electronics[40], 202255.5 mm20.76 mm(\approx\frac{1}{2}\lambda)Qian C et al., Light: Science & Applications[41], 202017.6 mm10 mm(\approx\frac{1}{2}\lambda)Aydogan Ozcan et al. Science advances[42], 2021뫘1 mm0.5 mm(\approx\frac{1}{2}\lambda)Lin X et al., Science[27], 20180.75 mm0.4 mm(\approx\frac{1}{2}\lambda)Zeng Z M et al., IEEE Photonics Technology Letters, 201910.6 um5 um(\approx\frac{1}{2}\lambda)모모In addition to generalising the system's physical parameters, introducing new optical elements, materials, and architectures has led to a better performance of the original system. In 2019, Qionghai Dai and Dr Xing Lin of Tsinghua University proposed a system design scheme to realise an optical diffractive deep neural network in Fourier space.[7] This system achieves the object recognition task by placing extremely compact multi-layer diffractive optical elements on the Fourier plane of the optical system. Also, with the utilisation of non-linear optical materials such as photorefractive crystals (SBN: 60) that synthesise a non-linear activation function, an improvement was made upon the first-generation D^2NN proposed by Xing Lin. The classification accuracy of the system on the MNIST dataset was improved from 91.75% to 95.4%. In the same year(2019), Aydogan Ozcan and colleagues created a differential system to enhance the performance of the optical diffractive neural network on image classification tasks[43]. To overcome the stringent non-negative limitations on the detector plane. Each class is assigned to corresponding detector pairs in their proposed differential design scheme. By utilising the inherent parallelism of the optical system, the entire system is divided into two parallel diffractive deep neural networks that can be jointedly trained. This reduces the crosstalk caused by the light coupling between "positive" and "negative" detectors, improving the normalised light intensity differences between detector pairs. For the handwritten digits(MNIST) classification task, the system achieved a 98.54% classification accuracy, the highest among all existing diffractive deep neural network computing systems.
모모These studies have extended the range of light sources in establishing the optical system and enhanced its performance. However, a diffractive deep neural network based on the long wavelength source is expensive and bulky and can be strongly attenuated by the vapour in the air. [44]Also, as the systems mentioned above use a coherent light source, server interference noise exists in the entire system. The interference noise will cause diffractions to interfere with each other during propagation, resulting in a series of chaotic and disorganised stripes. These stripes can even drown out the desired signals in severe cases.
모 On the other hand, interference noise imposes higher demands on the accuracy of the fabrication and assembly process. In 2020, researchers at the University of California, Los Angeles, analysed the impact of fabrication and alignment accuracy on the coherent light based diffractive deep neural network [45]. They found that minor assembly errors(\pm8\lambda error on x/y\ axis) can significantly reduce classification accuracy, from 91.75% to 12.8%, while perturbations(i.e. scaling, translation, and rotation) of the physical system lead an approximately 30% -70% drop in the classification accuracy [45C47]. Thus these physical bottlenecks limit the applications of?diffractive deep neural networks.
모Chromatic optical diffractive neural networks can effectively suppress the coherent noise caused by interference because the output is the summation of uncorrelated light intensity distributions in a narrow band. Though this chromatic system has higher information dimensionality bringing the prospect of multi-channel computing, it weakens the capability of processing complex information because all the computations are based on onefold light intensity.[48, 49]
2.3 Research Problems of Diffractive Deep Neural Network
모모Optical diffractive neural networks have seen significant growth and success since their inception, with researchers achieving many results. However, as this field is relatively new, much of the research is still in its early stages. This section highlights two main scientific problems in the field. Firstly, the design approach for physical system parameters in the optical diffractive deep neural network is based on the theory of maximum diffraction angle that lacks quantitative analysis methods. The feature size of the neurons in the system is determined by order of working wavelength, with an inverse relationship controlled by Equation(4-4). However, the theory of traditional maximum diffraction angle can only qualitatively describe the relationship between the two, suggesting that reducing the feature size of unit cells to \frac{1}{2}\lambda can lead to a successful optical computing system. When the system is integrated into a chip, the dimensionality is reduced, meaning a loss in connectivity. To maintain a high-accuracy computing performance in processing complex information, the number of neurons in a single layer will significantly increase. Therefore, a theoretical model that quantitatively describes the constraints between system parameters is vital to ensure an optimal design.
모모The second problem is the technical challenge in nanofabrication. The use of coherent light sources leads to severe interference noise. Increasing the number of I/O ports in the system while suppressing interference noise to maintain high performance requires high accuracy in the fabrication process.[50]  
 Foundation Concepts in Integrated Diffractive Deep Neural Network 
모모In this chapter, we cover the essential theoretical background for constructing the  ID^2NN. We start by introducing the principles and calculation methods of diffraction, followed by the complex-valued neural networks. These are the core building blocks of an integrated diffractive deep neural network.
3.1  Diffractive Optics
모모The relationship between optic theories is illustrated in Figure 31. Ray optics is the limit of wave optics when the wavelength is infinitesimally small. Electromagnetic optics encompasses wave optics, and it turns out that wave optics is a scalar approximation of electromagnetic optics.[29] The theory of quantum optics encompassing classical optical theories provides an explanation for virtually all optical phenomena. In this thesis, the design theory of the integrated deep diffractive neural network is based on wave optics with a focus on diffraction and will be discussed in detail in the following section.
모
Figure 31: The relationship between optic theories

모The way a 1-D wave \psi evolves in space and time is determined by the wave equation[37, 51]:
,,,?-2.뷍,x,t.-,?-2.,x-2..-,1-,c-2..,,?-2.뷍,x,t.-,?-2.,t-2..=0#,3-1..
, where x denotes position, t denotes time, and c denotes the propagation speed of light. The general solution to the wave equation is given as:
,뷍,x,t.=cos,kx-뷎t.#,3-2..
Here, k = \frac{2\pi}{\lambda} is the wave number, and \omega=\frac{2\pi}{T} is the angular frequency. The wave is periodic in space with period \lambda and periodic in time for a period of T. Interpretively, k converts a distance x to a phase shift, and \omega converts a time interval t to a phase shift. More generally, a plane wave travelling in the positive x-axis direction can be described as cos\left(kx-\omega t+\phi\right), where \phi is the initial phase shift. However, to make the computations simpler, as we will see later, we can convert them to complex notation using Euler's identity (e^{i\theta}=cos(\theta) + isin\left(\theta\right)):
,cos,kx-뷎t+?.=Re,,, ?-?,kx-뷎t+?....#,3-3..
The advantage of writing the expression in the exponential form is allowing us to separate time-dependence from space-dependence and straightforwardly compute the intensity of the superposition of two fields:
,, ?-?,kx-뷎t+?..=, ?-?kx.,e-?.,e--i뷎t.#,3-4..
Now, we can write the time-harmonic field in three dimensions:
\psi\left(x,y,z,t\right)\ =A\left(x,y,z\right)cos\left(\phi\left(x,y,z\right)-\omega t\right)
모모\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ =\ Re\left. \left\{{A\left(x,y,z\right)\ e}^{i\phi\left(x,y,z\right)}\right.e^{-i\omega t}\right\}
, =Re,,U,x,y,z..,e--i뷎t..#,3-5..
The spatial part of the field U\left(x,y,z\right) is factorised out in Equation (3-5), which is a complexed-valued function. It has both an amplitude and a phase which vary as a function of position. The amplitude indicates how large the oscillation is at a certain point, while the phase difference indicates the delay accumulated from the source point. The wave described by the scalar function:
,뷍,x,y,z,t.=U,x,y,z.,e--i뷎t.#,3-6..
should satisfy the 3D wave equation:
,,?-2.뷍,x,y,z,t.-,1-,c-2..,,?-2.뷍,x,y,z,t.-,?-2.,t-2..=0#,3-7..
, where \mathrm{\nabla}^2=\frac{\partial^2}{\partial^2x^2}+\frac{\partial^2}{\partial^2y^2}+\frac{\partial^2}{\partial^2z^2} (the Laplacian).
Plugging Equation (3-6) into Equation (3-7) and dividing out e^{-i\omega t} yields the Helmholtz equation:
,,,?-2.+,k-2..U,x,y,z.=0#,3-8..
It turns out that U\left(x,y,z\right) must obey this time-independent equation. Plane waves Equation (3-9) and spherical waves Equation (3-10) are the two solutions to the Helmholtz equation:
,,U-P. (r)=e^{ik\cdot r}=,?-?,,k-x.x+,k-y.y+,k-z.z..#,3-9..
,,U-S.,r.=,,?-?k,r..-4뷇,r..#,3-10..
, where k^2=k_x^2+k_y^2+k_z^2 and r denotes the position vector \left(x,y,z\right).
The time-averaged intensity of the optical field can be calculated as follows:
,I,r.=,,U,r..-2.#,3-11..
3.1.1 Propagation of Wave Fields
모모To model the propagation of monochromatic fields in free space, there are two ways to conceptualise this propagation. The first one is the angular spectrum method which is the addition of decomposed plane waves. The second is the Rayleigh-Sommerfeld formula which is the addition of impulse responses from point sources.[37] The following will discuss and analyse the two different propagation methods and their computational method.[51C53]
3.1.1.1 Angular Spectrum Propagation
모모Supposing a monochromatic complex-valued field U_0\left(x,y\right)\ is in the plane z\ =0 to compute the propagated field U_z\left(x,y\right) by a distance of z, the angular spectrum method yields the angular spectrum of the field by decomposing the initial field into plane waves. Each plane wave can propagate separately, as described in Equation (3-9). Then, by adding the plane waves together, we can find the propagated field U_z\left(x,y\right).The computational recipe of the angular spectrum method contains the following steps:
 Decompose the initial plane into plane waves by taking the Fourier transform, which gives the spectrum  {\hat{U}}_0\left(v_x,v_y\right):
{\hat{U}}_0\left(v_x,v_y\right)=\iint{U_0\left(x,y\right)e^{-2\pi i\left(v_xx+v_yy\right)}}dxdy
=\mathcal{F}\left\{\left. U_0\left(x,y\right)\right\}\right.\left(v_x,v_y\right)
,=F,,,U-0.,x,y...,,,k-x.-2뷇.,,,k-y.-2뷇..#,3-12..
 Calculate the field in the plane z by adding separately propagated plane waves together with weights {\hat{U}}_0\left(v_x,v_y\right) through the inverse Fourier transform:
U_z\left(x,y\right)=\iint{{\hat{U}}_0\left(v_x,v_y\right)e^{2\pi i\left(v_xx+v_yy+v_zz\right)}}dxdy
=\ \mathcal{F}^{-1}\left\{\left. {\hat{U}}_0\left(v_x,v_y\right)e^{2\pi iz\sqrt{\frac{1}{\lambda^2}-v_x^2-v_y^2}}\right\}\right.\left(x,y\right)
,=,F--1.,,,,U.-0.,,,k-x.-2뷇.,,,k-y.-2뷇..,e-i,k-z.z...,x,y.    , where   ,k-z.=,-,k-2.-,k-x-2.-,k-y-2..#,3-13..
As there is no restriction on the values for k_x\ and k_y, when k_x^2+k_y^2>k^2=\left(\frac{2\pi}{\lambda}\right)^2, k_z is imaginary, and Equation(3-13) will become:
,,U-z.,x,y.=,F--1.,,,,U.-0.,,,k-x.-2뷇.,,,k-y.-2뷇..,e--,,k-z..z...,x,y.#,3-14..
This leads to an evanescent field where higher spatial frequency (k_x, k_y) can not propagate because it decays exponentially with the propagation distance z.[51] Therefore, we can also conclude that the resolution of an image is limited by the wavelength of the illuminating light \lambda. Features in an image carried by wavelength which is less than \lambda can not be captured during propagation.
3.1.1.2 Rayleigh-Sommerfeld Propagation
모모The impulse response derived from the Helmholtz equation is shown in Equation (3-15) below. [51] Each point in the field is assumed to emit a spherical wave \frac{e^{ikr}}{r} whose amplitude is the same as that point in the field, but it is multiplied by a factor of \frac{z}{r}=cos\left(\theta\right) , which means the spherical wave attenuates when it propagates towards sideways.
,h(r)=,,ze-ikr.-,r-2..#,3-15..


Figure 32: Field propagation based on Rayleigh-Sommerfeld integral(a) The field that propagates through a small pinhole is the impulse response Equation (3-15)(b) The Rayleigh-Sommerfeld integral states that to propagate a field from an initial plane to another plane, all the impulse responses that originate from the initial plane must be summed together Equation (3-16)The Rayleigh-Sommerfeld integral can then be applied to find the total field at one point in the final plane[51]:
,U_z\left(x,y\right)=,1-i뷂.,--,U-0.,,x-'.,,y-'..,z-r.,,e-ikr.-r ..,d,x-'..,d,y-'..#,3-16..
, where r denotes the distance between the point in the initial plane \left(x^\prime,y^\prime,0\right)\ and the point \left(x,y,z\right) in the final plane:
,r=,-,,x-,x-'..-2.+,,y-,y-'..-2.+,z-2..#,3-17..
To calculate the Rayleigh-Sommerfeld integral computationally, a direct discretisation is performed[54]:
,,U-z.,x,y.=,1-i뷂.,m=1-M-,N=1-N-,U-0.,,x-'.,,y-'..,z-r.,,e-ikr.-r .붟x붟y..#,3-18..
The complex transform of the field between the two planes can be formulated as a matrix-vector multiplication:
\mathbit{U}_\mathbit{z}=\mathbit{W}\mathbit{U}_\mathbf{0}
,,,,U-z.,1,1.-?-,U-z.,M,N...=,,,1-i뷂.?h,,r-1..-?-,1-i뷂.?h,,r-M*N..-?-?-?-,1-i뷂.?h,,r-M*N..-?-,1-i뷂.?h,,r-1....,,,U-0.,1,1.?붟x붟y-?-,U-0.,M,N.?붟x붟y..#,3-19.. 
, where \mathbit{U}_\mathbf{0} and \mathbit{U}_\mathbit{z} represents the vectorised initial and propagated fields; \mathbit{W} is the matrix of multiplicative factors determined by impulse responses. It is important to note that \mathbit{W} is a symmetric matrix (\mathbit{W}=\mathbit{W}^\mathbit{T}), which can be leveraged to reduce the computational effort by making replicas below the diagonal.
모모The RayleighCSommerfeld diffraction(RSD) integral has been proved to be the only method that forecasted phase shift from the input to the output plane with no error, while the angular spectrum method distorted the phase map because of the corruptions of more minor features by applying Fourier transform.[55, 56] The main setback of RSD is the calculation complexity order of O\left(\left(M\times N\right)^2\right). Nonetheless, we have implemented a parallel-computed RSD that can be used to reduce the elapsed computation time. Taking advantage of the workstation installed with 8 Intel Core Xeon Gold 5218R, the parallelisation of the RSD can achieve a 210-time reduction of computation time compared with a standard CPU-based calculation on an Intel Core i7-8550U.
3.2 Complex-Valued Neural Network
모모The complex-valued neural networks (CVNNs) are a powerful modelling tool for domains where input data or signals can be naturally interpreted in complex numbers, such as optical signal processing.[54] In CVNNs, the weights, threshold values, input, and output signals are all complex numbers, and the activation function and its derivatives have to be well-behaved everywhere in the complex plane. They have also shown more powerful capability than real-valued neural networks in processing real-world signals. With complex weights, the neural network makes a significant step in gaining a higher functionality because multiplying by a complex number changes a value's magnitude and direction, which implies a mathematical rotation. The CVNNs rotate the signals as they pass through. As shown in Figure 33(b), in the feedforward complex-valued neural network, the inputs z_n are sent to a complex-valued neuron, each corresponding to a complex weight; then we weight and sum the inputs, perform the non-linear activation, and finally, obtain the output y_k\left[22,26\right]. The training aims to get the output close to the ground truth[58]. It is constantly updated to optimise the training process until the network is converged. In the following statement, the form of y_k is as follows:
모,,y-k.=,,i=1-n-,w-i.*,z-i...#,3-20..
모
(a)
(c)
(b)
Figure 33: Mechanism of CVNNs(a) Mapping normalised inputs to the complex unit circle.(c) The model of feedforward complex-valued neural network.(b) Structure of a complex-valued neuron.모모In order to work with inputs that are from the real world but not complex numbers like image pixels and want the network to give real number answers or even classification categories, we need to prepare inputs and map the outputs. Normalised real number inputs can be transformed into the complex unit circle through:
,z=,?-j2뷇x.,x뫍,0,1.#,3-21..
Through this transformation, the incoming data can be best spread out over the complex domain with relatively high variance, giving the network the best chance of learning. 
Design Framework of Integrated Diffractive Deep Neural Network
모모The integrated diffractive neural network (ID^2NN) is implemented on photonic waveguides or photonic chips, which are characterised by comprising an input layer, diffraction layers(hidden layers), and an output layer, as shown in Figure 41. This chapter will provide the design theory of ID^2NN as an image classifier.

Figure 41: Diagram of integrated diffractive deep neural network
모모The integrated diffractive deep neural network design framework relies on the fully connected topology that constrains the relationship between physical parameters for achieving maximum connectivity within the successive diffraction layers. The fully connected topology is the foundation for designing integrated diffractive neural networks. The design process starts with setting the system's structural parameters and establishing a fully connected implementation.  These system parameters are then introduced into the forward inference and training algorithms for the ID^2NN . For image classification tasks, the design process of the ID^2NN can be summarized as follows:
 Load the data set's attributes into the original complex field to obtain a new input complex field.
 Construct the forward propagation model of ID^2NN based on the diffraction theory.
 Define the loss function to measure the difference between the desired intensity and the actual intensity of the output and train ID^2NN through error backpropagation algorithms.
 Map the trained neuron's value to the physical unit cell structure that can generate a corresponding phase delay.

Figure 42: Computation graph for forward inference and training of \mathbit{I}\mathbit{D}^\mathbf{2}\mathbit{NN}4.1 Connectivity of Integrated Diffractive Deep Neural Network
모모The fully connected topology is the basis for designing diffractive neural networks[27, 59], which implies that every neuron in a layer can be connected to all neurons in the next layer. In the corresponding optical system, neurons are represented by micro-structure unit cells that have the ability to modulate the incoming light, and the connectivity is realised physically by diffraction. Therefore, the diffraction angle should be sufficiently large to ensure complete signal transmission between neurons.
(a)
(b)

Figure 43: Schematic diagram of the fully connected topology of \mathbit{I}\mathbit{D}^\mathbf{2}\mathbit{NN}(a) Wave propagation in \mathbit{I}\mathbit{D}^\mathbf{2}\mathbit{NN}(b) The relationship between physical parameters within the fully connected implementation of \mathbit{I}\mathbit{D}^\mathbf{2}\mathbit{NN}모모When light is normally incident on?the micro-structure unit cell, as shown in Figure 43, the diffracted light will produce an optical path difference of 2\mathrm{\Delta d}\cdot sin\left(\varphi_{max}\right) which is governed by the grating equations:
모,2붟d?sin,,뷋-max..=m?뷂#,4-1..
모,,x-m.=m?,뷂L-2붟d.#,4-2..
, where \mathrm{\Delta d} is the feature size of a unit cell, m=0,\pm1,\pm2,\ldots is the integer denoting the diffraction order[51, 52]. The maximum diffraction angle \varphi_{max} for the optical diffractive deep neural network can be considered when \ \ m=1:
,2붟d?sin,,뷋-max..=뷂#,4-3..
The above Equation (4-3) can be rewritten as:
,,뷋-max.=si,n--1.,,뷂-2붟d..#,4-4..
The maximum diffraction angle for the optical diffractive deep neural network \varphi_{max} thereby can be qualitatively described by Equation(4-4) with two parameters: \lambda\ and \mathrm{\Delta d}. \varphi_{max} is an indicator of the connectivity between two adjunct diffractive layers, which is proportional to \lambda and inversely proportional to \mathrm{\Delta d}. Thus, as a general rule, the longer wavelength of the light source and the smaller feature size of the unit cell will provide more sufficiency to achieve a fully connected diffractive deep neural network in an actual optical environment. Additionally, in the scenario with fixed wavelength, the feature size of the unit cell is reduced to the scale of sub-wavelength(\approx\frac{1}{2}\lambda) or even smaller to realise a 90뫢 maximum diffraction angle:
,,뷋-max.=si,n--1.,,뷂-2붟d..=si,n--1.,,,뷂-2?,,1-2.뷂....=si,n--1.,1.=90뫢#,4-5..
모모Figure 43 (b) presents a schematic diagram of the fully connected topology of the integrated diffractive deep neural network. The implementation of this topology is influenced not only by the working wavelength 뷂 of the light source and the feature size 붟d of the neuron (unit cell) but also by two physical quantities: the spacing distance D between two layers and the number of neurons per layer N. The fully connected implementation of ID^2NN should result from a quantitative relationship that involves the four aforementioned physical parameters. For a propagation distance D between two adjacent diffraction layers, the range of diffraction  R for each unit cell  can be expressed as:
모,R=D?,tan-,뷋-max..#,4-6..
The length of the diffraction layer L is determined by the number of neurons per layer N and the feature size \mathrm{\Delta d} :
모,L=N?붟d#,4-7..
Regardless of the dynamic setting of the layer spacing and the length of the diffraction layer, the  range of diffraction must cover the entire length of the next diffraction layer so that a fully connected topology can be realized:
모,R뫟L#,4-8..
That is밐
모,,D?tan-,,뷋-max...뫟N?붟d#,4-9..
By rearranging Equation (4-9), we can get:
,D뫟,N붟d-,tan-,,뷋-max.)...#,4-10..
Because of \tan{\left(\varphi_{max})\right.}=\frac{sin{\left(\varphi_{max}\right)}}{cos{\left(\varphi_{max}\right)}}=\frac{sin{\left(\varphi_{max}\right)}}{\sqrt{1-sin{\left(\varphi_{max}\right)^2}}}  and \sin{\left(\varphi_{max}\right)}=\frac{\lambda}{2\mathrm{\Delta d}} , the above equation can be written as:
D\geq\frac{N\mathrm{\Delta d}}{\frac{\lambda}{2\mathrm{\Delta d}}/\sqrt{1-\left(\frac{\lambda}{2\mathrm{\Delta d}}\right)^2}}
모,D뫟N붟d?,-,4붟,d-2.-,뷂-2..-1.#,4-11..
Combining Equations (4-4) and Equations (4-11), we can obtain the following:
모,,,,뷋-max.=si,n--1.,,뷂-2붟d..-D뫟N붟d?,-,4붟,d-2.-,뷂-2..-1.. .#,4-12..
Equation (4-12) quantitatively describes the constraints among the physical parameters required for a fully connected ID^2NN architecture. When these conditions are met, the system can ensure sufficient interconnection to transmit information between two layers. We will use Equation (4-12) as the theoretical basis for designing the parameters in the ID^2NN system. The table below shows the parameters of  ID^2NN designed in this thesis:
Table 41: System design parameters of \mathbit{I}\mathbit{D}^\mathbf{2}\mathbit{NN}
System Design ParametersParameter ValueWavelength in free space1.55\times{10}^{-6}\ mNumber of neurons per layer300Neuron feature size0.5\times{10}^{-6}\ m\ Distance between diffraction layers300\times{10}^{-6}\ m\ Number of hidden layers5Refractive index of diffraction layer1.0Refractive index of propagation medium3.454.2 Physical Input to the Integrated Diffractive Deep Neural Network 
모모Figure 44 shows the handwritten digit dataset MNIST (Modified National Institute of Standards and Technology), ranging between 0 to 9. The MNIST dataset originates from the United States National Institute of Standards and Technology and contains 70,000 image samples. [60]Among these, 55,000 images serve as training set samples, 5,000 as validation set samples, and 10,000 as entirely new test set samples. This data set is widely collected from employees of the United States Census Bureau and some high school students in the United States. The MNIST dataset is recognized as one of the world's most widely used and authoritative training sample repositories. The sample construction of the MNIST dataset conforms to statistical rules and exhibits generality. The dataset features rich sample characteristics and moderate sample size. Most significantly, the MNIST dataset is freely available and easily accessible. These attributes make it one of the most commonly used training data in deep learning and the research of optical neural networks.
모모The Fashion MNIST dataset ( shown in Figure 45), containing more complex images with a higher difficulty level, is an alternative to the traditional MNIST dataset for image classification tasks.[61] It offers a more challenging benchmark for deep learning algorithms in image classification research. This thesis will use both of the datasets to evaluate the effectiveness of ID^2NN.

Figure 44: Some sample images for each class of the MNIST dataset

Figure 45: Some sample images for each class of the Fashion MNIST dataset

모모Each image in these datasets consists of 28x28 pixels, with each pixel represented by a grayscale value. Traditional artificial neural networks can directly extract the pixel value of the images from the dataset for learning and training. In contrast, integrated diffractive deep neural networks rely on physical entities, so it is necessary to load the pixel values into the optical input field accordingly. The input information can be encoded in the amplitude or phase channels. The information loading steps are explained respectively below. 
4.2.1 Amplitude Channel Encoding of Input Field
모모The pixel values were converted into binary format (0/1) to simulate the light transmission and blocking scenarios, endowing the binarized input with actual physical contour information. This procedure relies on micro-nano manufacturing techniques to create tangible input entities. A pixel grid with a value of 1 represents the presence of light, which will propagate forwards as a light source through diffraction, thus enabling information to be loaded in the amplitude channel. 
모모To minimize power consumption and area overhead, non-essential characteristics for image classification are removed. Each pixel within the training image serves as a feature for the ID^2NN. The dataset is downscaled to N\le784 features, with N ranging from 36 to 324, to determine the optimal number of observed features. Classification accuracy is obtained for the downsampled data in Python simulations of ID^2NN. The optimal number of observed features is N=100\left(10\times10\right), which corresponds to a 91.6% accuracy for the MNIST dataset. Figure4-6  shows the binarized and downsampled N=100\  image. Flattening is necessary to function the integrated diffractive deep neural network in a two-dimensional plane.
모

Figure 46: Handwritten digits from the MNIST dataset(a) Original image with default resolution (28뫄28)(b)  Selected pixels shown with light squares(c)  Selected pixels in the original image(d)  Downsampled image with 10뫄10 pixels.(e) Flattened image(1뫄100)4.2.2 Phase Channel Encoding of Input Field
모모The input light source of the system is a series of coherent light in parallel, which can be denoted as Ae^{j\varphi}. The refractive index of the input layer is smaller than the refractive index of the guided medium, and when the light propagates through the input layer, a phase delay is imposed. With this, we can load the input data into the phase channel of the optical field. If the input data consists of the value  x_1,x_2,x_3,\ldots,x_i , where x_i\in\left[0,1\right], and the optical source has an initial phase of zero, then we can express the optical field delayed by the input layer as Ae^{j2\pi x_1},Ae^{j2\pi x_2},Ae^{j2\pi x_3},\ldots,Ae^{j2\pi x_i}. The phase delay can be achieved by varying the unit cell length in the input layer, thus enabling data attributes to be loaded in the phase channel.
4.3 Forward Propagation of Integrated Diffractive Deep Neural Network
모모For the guided wave system, the wavelength of light  inside the medium depends on the refractive index of the medium:
,,뷂-g.=,뷂-n.#,4-13..
, where \lambda\ is free space wavelength, n is the refractive index of the guided material/propagation medium, and \lambda_gis the wavelength in that material.[31] 
모모According to the Rayleigh-Sommerfeld diffraction equation, Equation (3-16), when waves propagate to the position \left(x_i,y_i,z_i\right) in the l^{th} layer, it will generate the following optical field at point i  located at \left(x,y,z\right) in the next layer:
모,,w-i-l.,x,y,z.==,z-,z-i.-,r-2..,,1-2뷇r.+,1-j,뷂-g...,e-,j2뷇r-,뷂-g...#,4-14..
, where w_i^l is defined as the propagation coefficient. \lambda_g is the wavelength of optical  and r=\sqrt{\left(x-x_i\right)^2+\left(y{-y}_i\right)^2+\left(z{-z}_i\right)^2} represents the Euclidean distance between the two points.
Thus, the output of the neuron at point \left(x_i,y_i,z_i\right) in the l^{th} layer is the sum of the outputs of all neurons at the position \left(x,y,z\right) in the {l-1}^{th} layer multiplied by the complex transmission coefficient for that neuron (at that point), and  w_i^l\left(x,y,z\right):
,,n-i-l.,x,y,z.=,w-i-l.,x,y,z.?,t-i-l.,,x-i.,,y-i.,,z-i..?,k--,n-k-l-1.,,x-i.,,y-i.,,z-i...#,4-15..The process of forward propagation of ID^2NN can therefore be summarised as follows:
,,,,,n-i-l.,x,y,z.=,w-i-l.,x,y,z.?,t-i-l.,,x-i.,,y-i.,,z-i..?,m-i-l.,,x-i.,,y-i.,,z-i..-,m-i-l.,,x-i.,,y-i.,,z-i..=,k--,n-k-l-1.,,x-i.,,y-i.,,z-i.. ..-,t-i-l.,,x-i.,,y-i.,,z-i..=,붸-i-l.,,x-i.,,y-i.,,z-i..,e-j,?-i-l.,,x-i.,,y-i.,,z-i...  ..#,4-16..
The two latent variables {\ \ \alpha}_i^l\  and \phi_i^l should be confined to the range \left(0,\ 1\right) and \left(0,\ 2\pi\right) respectively. Equation (4-16) represents a recursive model of the forward propagation process of {ID}^2NN.  Suppose the entire ID^2NN consists of M layers (M\geq l\geq1), and in order to hold that model, it is necessary to know the initial value of the entire recursive relationship, that is, the value of \sum_{k}{n_k^0\left(x_i,y_i,z_i\right)\ }when M=l=1. In Section 4.2 of this thesis, we have discussed the encoding methods of the input data. In fact, the input layer is the 0^{th} layer of the {ID}^2NN, and the encoded optical field carrying the physical information is that initial value. The forward propagation of the field between two successive layers in {ID}^2NN can be calculated by matrix multiplication[5, 62]: 

\mathbit{U}^\mathbit{l}=\mathbit{W}\mathbit{U}^{\mathbit{l}-\mathbf{1}}\odot\mathbit{T}^\mathbit{l}
,,,,U-1-l.,,x-1.,,y-1.,,z-1..-?-,U-k-l.,,x-i.,,y-i.,,z-i....=,,,w-1.,,r-1..-?-,w-k.,,r-k..-?-?-?-,w-k.,,r-k..-?-,w-1.,,r-1....,,,U-1-l-1.,,x-1.,,y-1.,,z-1..?붟x붟y-?-,U-k-l-1.,,x-i.,,y-i.,,z-i..?붟x붟y..뫔,,,t-1-l.,,x-1.,,y-1.,,z-1..-?-,t-k-l.,,x-i.,,y-i.,,z-i....#,4-17..

Here we use U_k^{l-1}\left(x_i,y_i,z_i\right) as the alternative notation for n_k^{l-1}\left(x_i,y_i,z_i\right), because we want to emphasise that it is an optical field. 
모모The (M+{1)}^{th}\ layer is the output layer, in which the detectors measure the intensity of the resulting field in predefined regions:
,,s-i-M+1.=,,,m-i-M+1..-2.#,4-18..
모모Obviously, the entire integrated diffractive deep neural structure is similar to a  fully connected complex-valued neural network. In contrast to the complex-valued neural network, ID^2NN works on the physical plane using the interference of waves. The output of each neuron in a CVNN discussed in Section 3.2  is y = ??(????), where weight ?? is the trainable parameter. But for an integrated diffractive deep neural network, the output of a unit cell is given as y = ??????, where ?? is a  hyperparameter determined by diffraction that can be tuned by adjusting the distance between two layers. At the same time, the multiplicative bias ?? is the trainable parameter that can be trained through backpropagation algorithms. The trained neuron's phase value can be mapped onto the different phase delays in terms of physical structures, and the corresponding phase delays are produced by varying the length of the unit cell.
4.4  Error Backpropagation of Integtared Diffractive Deep Neural Network
모모To utilize the error backpropagation algorithm,  it is necessary to construct the loss function(E) based on the optical field intensity distribution at the output layer. Mean Square Error (MSE)[63] and Softmax Cross Entropy (SCE)[64] are two commonly used loss functions in the field of optical diffractive neural networks. 
모모Specifically, for a phase-only diffractive deep neural network, the backpropagation algorithm is used to train the distribution of \phi_i^l. When we use MSE as the loss function, the actual light intensity of the output plane is s_k^{M+1}\ =\left|m_k^{M+1}\right|^2 and the expected light intensity is g_k^{M+1}. Then the MSE loss function can be expressed as:
모,E,,?-i-l..=,1-k.,k--,,,s-k-M+1.-,g-k-M+1..-2..#,4-19..
, where k refers to the number of measurement points at the output plane.
모모Compared with the MSE loss function based on the light intensity distribution of the entire output plane, the SCE loss function only focuses on the normalised light intensity distribution in the detector region of the output plane, ignoring the light intensity outside the detector region. For the N-class image classification task with N detection regions included, the normalised intensity distribution \widetilde{s_n} of the n^{th}\ detector region can be calculated as:
,,,s-n..=,,s-n.-max,,,s-n....#,4-20..
Different normalisation methods can also be used before applying the softmax function to get the probability distribution \widehat{s_n} for each class.The SCE loss function E\left(\phi_i^l\right) can be written as:
,,,,,s-n..=,exp,,,s-n...-,n-N-exp,,,s-n.....-E,,?-i-l..=-,n-N-,,g.-n.log,,,s-n......#,4-21..
, where {\widetilde{g}}_n is the expected normalised field intensity. 
모모Based on the chosen loss function, the optimisation problem for a {ID}^2NN design can be written as:
,,,min-,?-i-l..-E,,?-i-l...,0뫞,?-i-l.뫞2뷇#,4-22..
The weights(phase) of each diffractive layer can be iteratively updated through backpropagation algorithms(i.e. Adam optimiser) so that the loss will continuously drop-down, meaning that the actual intensity distribution is approaching the desired result. 
모모To update the weights in the network through a gradient descent optimization process, it is necessary to compute the gradient of the loss function with respect to the training variables. In the case of using MSE  as the loss function:
모,,?E,,?-i-l..-?,?-i-l..=,2-k.,k--?.,,s-k-M+1.-,g-k-M+1..?,?,s-k-M+1.-,?-i-l..=,2-k.,k--?.,,s-k-M+1.-,g-k-M+1..?,?,,,m-k-M+1..-2.-?,?-i-l..#,4-23..
By expressing  \left|m_i^{M+1}\right|^2 as \ \left(m_i^{M+1}\right)^\ast m_i^{M+1} , where  \left(m_i^{M+1}\right)^\ast is the complex conjugate of m_i^{M+1}, we can get:
모모,,?,,,m-i-M+1..-2.-?,?-i-l..=,?,,,m-i-M+1..-*.,m-i-M+1.-?,?-i-l..#,4-24..
The derivative of a function with absolute value can be calculated as follows, where A=a+bi,
\frac{\partial|A|^2}{\partial x}=\left(a+bi\right)\frac{\partial\left(a-bi\right)}{\partial x}+\left(a-bi\right)\frac{\partial\left(a+bi\right)}{\partial x}
,=2,a,?a-?x.+b,?b-?x..=2?,real-,,A-*.?,?A-?x.. .#,4-25..
Hence, Equation (4-24) can be simplified as:
모모,,?E,,?-i-l..-?,?-i-l..=,4-k.,k--?.?,,s-k-M+1.-,g-k-M+1..?,real-,,,,m-k-M+1..-*.?,?,m-k-M+1.-?,?-i-l....#,4-26..
For the M^{th} layer:
\frac{\partial m_k^{M+1}\left(x_k,y_k,z_k\right)}{\partial\phi_i^{l=M}}=\frac{\partial\sum_{k1}\hairsp\hairsp n_{k1}^M\left(x_k,y_k,z_k\right)}{\partial\phi_i^{l=M}}
=\frac{\partial\sum_{k1}\hairsp\hairsp w_{k1}^M\left(x_k,y_k,z_k\right)\cdot t_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)\cdot m_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)}{\partial\phi_i^{l=M}}
t_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)=a_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)\cdot\exp{\left(j\phi_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)\right)}
,,?,m-k-M+1.,,x-k.,,y-k.,,z-k..-?,?-i-i=M..=j?,t-i-M.,,x-i.,,y-i.,,z-i..?,m-i-M.,,x-i.,,y-i.,,z-i..?,w-i-M.,,x-k.,,y-k.,,z-k..#,4-27..
We can use the chain rule of differentiation to obtain the phase gradient for layers L less than M. For the \left(M-1\right)^{th} layer:
\frac{\partial m_k^{M+1}\left(x_k,y_k,z_k\right)}{\partial\phi_i^{l=M-1}}=\frac{\partial\sum_{k1}\hairsp\hairsp w_{k1}^M\left(x_k,y_k,z_k\right)\cdot t_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)\cdot m_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)}{\partial\phi_i^{l=M-1}}
=\frac{\partial\sum_{k1}\hairsp\hairsp w_{k1}^M\left(x_k,y_k,z_k\right)\cdot t_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)\cdot\sum_{k2}\hairsp\hairsp n_{k2}^{M-1}\left(x_{k1},y_{k1},z_{k1}\right)}{\partial\phi_i^{l=M-1}}
=\frac{\partial\sum_{k1}\hairsp\hairsp w_{k1}^M\left(x_k,y_k,z_k\right)\cdot t_{k1}^M\left(x_{k1},y_{k1},z_{k1}\right)\cdot\sum_{k2}\hairsp\hairsp w_{k2}^{M-1}\left(x_{k1},y_{k1},z_{k1}\right)\cdot t_{k2}^{M-1}\left(x_{k2},y_{k2},z_{k2}\right)\cdot m_{k2}^{M-1}\left(x_{k2},y_{k2},z_{k2}\right)}{\partial\phi_i^{l=M-1}}
,=j?,t-i-M-1.,,x-i.,,y-i.,,z-i..?,m-i-M-1.,,x-i.,,y-i.,,z-i..?,k1--?.?,w-k1-M.,,x-k.,,y-k.,,z-k..?,t-k1-M.,,x-k1.,,y-k1.,,z-k1..?,w-i-M-1.,,x-k1.,,y-k1.,,z-k1..#,4-28..
Similarly, for the {(M-2)}^{th} layer and all layers up to the\ L^{th} layer, the gradient can be calculated as follows:
모모,,?,m-k-M+1.,,x-k.,,y-k.,,z-k..-?,?-i-l=M-2..=j?,t-i-M-2.?,m-i-M-2.?,,k-1.--?.?,w-k1,k-M.?,t-k1-M.?,k2--?.?,w-k2,k1-M-1.?,t-k2-M-1.?,w-i,k2-M-2.#,4-29..
모모,,?,m-k-M+1.,,x-k.,,y-k.,,z-k..-?,?-i-l=M-L..=j?,t-i-M-L.?,m-i-M-L.?,,k-1.--?.?,w-k1,k-M.?,t-k1-M.?,kL--?.?,w-kL,kL-1-M-L+1.?,t-kL-M-L+1.?,w-i,kL-M-L.#,4-30..
In the case of using SCE  as the loss function, the gradient can be derived as follows:
,,?E,,?-i-l..-?,?-i-l..=,?E,,?-i-l..-?,,,m-i-M+1..-2..?,?,,,m-i-M+1..-2.-?,?-i-l..=,,,s-n..-,,g.-n..?2,?real-,,,,m-i-M+1..-*.?,?,m-i-M+1.-?,?-i-l....#,4-31..
4.5 Unit Cell Design and Neural Value Mapping
모모The term "neuron value mapping" in designing an integrated diffractive deep neuron network refers to using phase delays imposed on the optical field through slots of different lengths. The phase delays (or phase distribution) are obtained from the training in the computer, as discussed in the last section.  The designed unit cells are rectangular etched arrays created in the  Silicon-On-Insulator(SOI), as shown in Figure 47 (a). The silicon membrane of the SOI has a thickness of 250 nm, while the SiO2 insulator layer is 2 ?m thick. The feature size of the unit cell (\mathrm{\Delta d}) is set to be 500\ nm which is less than half of the wavelength. The large contrast in refractive index between silicon and silicon dioxide will enable a 0\ to 2\pi phase delay while maintaining a high transmission. The phase delay/ phase shift and transmission can be controlled by varying the width and length of the slot.[65]
모모To precisely map the value of the neuron (the phase shift) to the corresponding physical structure. A parameter sweep of the slot in Lumerical FDTD has been performed under the transverse electric(TE) optical mode with the wavelength of  1550\ nm. The simulated result of phase and amplitude retardation of transmission as functions of both the slot's width and length are shown in Figures 47 (b) and (d). By maintaining the slot width at 0.14\ \mu m and varying the slot length from 0.2 to 2.5 뷃m, a phase shift from 0 to 2뷇, along with a transmission greater than 90%, can be simultaneously achieved, as shown in Figure 47 (c). The relationship between slot length (at fixed slot width of 0.14\ \mu m) and phase shift can be described as a straightforward linear function,
,L=0.32626?,10--6.??#,4-32..
, where 0.32626\cdot{10}^{-6} denotes the average of the slope. It should be noted that a 2뷇 phase shift can be obtained with a smaller variation in slot length with a wider slot, but the transmission significantly decreases. 
Figure 47: The design principle of unit cells in integrated diffractive deep neural network(a) A schematic view of unit cells with a feature size \mathbit{\Delta d}\ =\ \mathbf{500}\ \mathbit{nm}(b) The simulated phase shift versus slot length and width. Dashed white curves share the same phase and are spaced by 2뷇.(c) The simulated amplitude and phase of the transmission in relation to slot length are examined, with the slot width fixed at 140 뷃m.(d) The simulated transmission and phase shift versus slot length and width.
Figure 48: Schematic of the integrated diffractive deep neural network
Analysis of Loss Functions and Number of Diffraction Layers in Integrated Diffractive Deep Neural Networks
모모In the previous chapter, we developed the design framework for the integrated diffractive deep neural network. To further refine the overall design methodology of the integrated diffractive deep neural network, we need to investigate the optimization criteria within the training algorithm, such as the selection for different loss functions and the scale of the network, including the number of integrated diffraction layers and the number of neurons in each layer. By investigating the performance disparities in integrated diffractive deep neural networks resulting from these factors, we can justify our choice of a 5-layer integrated diffraction structure and the softmax cross-entropy loss for training the system in this thesis.
5.1 Analysis of Loss Functions in Integrated Diffractive Deep Neural Networks
모In the following, we will compare and analyze the impact of two loss functions on accuracy and the system output. For a randomly selected test image(handwritten digit "9") shown in Figure 51 (a) as an example, the integrated diffractive deep neural network constructed with the Softmax Cross-Entropy(SCE) loss function produces an output light intensity distribution as depicted in Figure 52 (b). In contrast, the integrated diffractive deep neural network constructed with the Mean Square Error(MSE) loss function yields an output light intensity distribution as illustrated in Figure 52 (a). By comparing and analyzing Figure 52 (a) and Figure 52 (b), it can be observed that both types of loss functions enable accurate classification of the handwritten digit "9". The maximum light intensity of the output field is concentrated in the detector region labelled "9". Moreover, with respect to the energy distribution inside the detector region, the MSE one is more focused, while the SCE one is more dispersed.
Figure 51: Contrastive analysis I between MSE loss function and SCE loss function(a) The input image: handwritten digit 9(b) The intensity distribution of the output field based on the MSE loss function(c) The intensity distribution of the output field based on the SCE loss function모모The light intensity distribution of the ten detector regions in Figure  5-1 (b) and Figure 5-1 (c) is then extracted and calculated in relative energy  distribution using the following formula:
모,,P-i.=,,E-i.-,E-1.+,E-2.+몴+,E-n..#,4-33..
, where E_i is the energy detected in the i^{th} region, and n is the number of detectors. Figure 5-2  presents the calculated result in histograms, respectively.

Figure 52: The contrastive analysis II between MSE loss function and SCE loss function(a) Relative energy distribution of the detector regions based on MSE loss function(b) Relative energy distribution of the detector regions based on the SCE loss functionThe integrated diffractive deep neural network built with the MSE loss function results in the detector region labelled "9", accounting for around 50% of the total optical energy across all regions, whereas the network with the SCE loss function has only 43%. The MSE loss function provides a higher signal-to-noise ratio in the detection plane. However, when considering numerical classification accuracy for a new test set, the integrated diffractive deep neural network using the cross-entropy loss function shows higher accuracy. For the MNIST dataset, the network with SCE loss achieves 91.60% accuracy, while the network using MSE loss reaches only 85.70% for the same test set. The confusion matrixes for both cases are shown in the following figure.
Figure 53: The contrastive analysis III between MSE loss function and SCE loss function(a) The confusion matrix for the MNIST dataset using an integrated diffractive deep neural network based on the MSE loss function(b) The confusion matrix for the MNIST dataset using an integrated diffractive deep neural network based on the SCE loss function
Table 51: Summary of classification accuracy for a 5-Layer  {\mathbit{ID}}^\mathbf{2}\mathbit{NN} with different types of loss functions
Loss FunctionDatasetAccuracyMeas Square ErrorMNIST85.70%Softmax Cross EntropyMNIST91.60%Meas Square ErrorFashion-MNIST71.06%Softmax Cross EntropyFashion-MNIST74.71%모모Through the contrastive analysis (see Table 5-1), a conclusion can be drawn that with the softmax cross-entropy loss function, the system sacrifices the signal-to-noise ratio of the output signal but yields higher classification accuracy. In contrast, the mean square error loss function has led to a lower classification performance but a higher signal-to-noise ratio of the output signal. Equation (4-19) and Equation (4-21) show the difference between the two loss functions, which is the crucial factor leading to this phenomenon: the MSE affects the intensity distribution among all the detectors while the SCE uses an interclass competition mechanism, focusing on the intensity distribution within the detector area while disregarding the intensity distribution outside of it.
모모This thesis focuses on employing the softmax cross-entropy as the loss function. We highlight the characteristic of high numerical classification accuracy, which will bring more freedom to the system design process. The drawback of a lower signal-to-noise ratio existing in this approach can be compensated by increasing the input power.  In summary, the choice of which loss function to use in constructing an integrated diffractive deep neural network should be determined based on the specific requirements. 
5.2  Analysis of  Number of Layers in Integrated Diffractive Deep Neural Networks
모모Utilizing a trained system based on the softmax cross-entropy loss function, we will investigate the integrated diffractive deep neural network constructed with parameters from Table 41. By performing simulations in the Python environment, we aim to analyze and compare the changes in numerical classification accuracy for image classification tasks on the  MNIST dataset as the number of diffraction layers in the system varies.
모모Generally, a neural network with more layers and neurons exhibits enhanced classification capabilities. However, for integrated diffractive deep neural networks, adding layers also increases the complexity of the physical model. As a result, factors such as alignment errors, deformation errors, transmission rates, and diffraction crosstalk become more pronounced, negatively affecting the overall performance. Instead, increasing the neurons in each layer can capitalize on the benefits of parallel optical processing. Therefore, in this thesis, each layer consists of 300 neurons based on a fully connected architecture. This configuration allows for increased neurons per diffraction layer while maintaining reasonable interlayer distances and minimizing optical loss.
모모The impact of varying the number of diffraction layers on numerical classification accuracy is summarized in Figure 5-4. For a test set of 10,000 samples, a five-layer integrated diffractive deep neural network achieves 91.6% accuracy, with the confusion matrix shown in Figure 5-5 (a). When reduced to three layers, the accuracy is 87.44%, and Figure 5-5 (b) shows the corresponding confusion matrix. When reduced to a single layer, the accuracy declines to 70.42%, and the confusion matrix is presented in Figure 5-5 (c).
Figure 54: Classification accuracy of integrated diffractive deep neural networks with different numbers of diffraction layersFigure 55: Confusion matrixes of integrated diffractive deep neural networks with different number of diffraction layers(a) The confusion matrix of the integrated diffractive deep neural network with 1 layer(b) The confusion matrix of the integrated diffractive deep neural network with 3 layers(c) The confusion matrix of the integrated diffractive deep neural network with 5 layers
모모Figure 5-6 shows the loss and accuracy values for 1-layer, 3-layer and 5-layer integrated diffractive deep neural networks during the learning procedure. The general rule in a traditional artificial neural network that more layers lead to more robust system performance also holds for integrated diffractive deep neural networks. However, unlike traditional artificial neural network models, increasing the number of diffraction layers in integrated diffractive deep neural networks not only escalates the economic and time costs linked to micro-nano fabrication processes but also amplifies the complexity of interlayer alignment and experimental errors. In comparison, adding layers to traditional artificial neural network models simply entails increasing matrix dimensions during the learning and training process, with no additional costs other than increased computational workload and code complexity. While it is feasible to construct integrated diffractive deep neural network systems with more diffraction layers, such as seven or even ten layers, this study opts for a 5-layer diffraction structure, taking into account factors including fabrication costs and experimental complexity, for the system design and related research of integrated diffractive deep neural networks.
Verification of Designed Integrated Diffractive Deep Neural Network
모모To numerically demonstrate the performance of the designed integrated diffractive deep neural network, we employ the prototypical machine learning task of image classification using the MNIST dataset, with the downsampling and loading process detailed in Section 4.2.1. One hundred binarized inputs will be loaded onto the corresponding input narrow waveguides in the amplitude channel, and the classified results are ten categories, ranging from 0 to 9, respectively. The parameters within the entire ID^2NN  system is pre-trained (refer to Section 4.4). Once the design is finalized and fabricated (see Section 4.5), the ID^2NN operates entirely optically. To validate the functionality of the integrated diffractive deep neural network, both Python-based simulations and Lumerical FDTD simulations are used.
6.1 Numerical Simulation of the Integrated Diffractive Deep Neural Networks
모모Simulating large-scale integrated diffractive deep neural networks in Lumerical FDTD requires substantial computational resources and consumes significant memory. Therefore, we use the Rayleigh-Sommerfeld diffraction equation to perform numerical simulations of the 5-layer integrated diffractive deep neural network in a Python environment, with system parameters as shown in Table 41. Figure 61 shows the normalized \left|E_y\right|^2distribution of the obtained through simulation in Python. From top to bottom, the input corresponds to handwritten digits from 0 to 9. The integrated diffractive deep neural network can accurately perform the classification task for handwritten digits.

모모In order to validate the functionality of the integrated diffractive deep neural network in Lumerical FDTD, we scale down its size. Here, we use a single diffraction layer with 100 neurons and a distance of 100?m among each other for the input layer, diffraction layer and output layer. The simulation results are shown in Figure 6-2. 
모모Here, we must mention that mismatches exist in the Python simulations and the one in FDTD. This indicates that the classification accuracy in a real system will be lower than the accuracy reported in this thesis. We also find that expanding the scale of the integrated diffractive deep neural network, especially the number of diffraction layers, exacerbates the model-system mismatch. The model-system mismatch between our model (Section 4.3) and the system in Lumerical FDTD can be attributed to the following factors: (i) The Rayleigh-Sommerfeld diffraction equation serves as an approximation and does not accurately describe the diffraction process. (ii) The coupling effect caused by the length differences of the neighbour slots is non-negligible, causing the phase shift produced by an individual slot in the diffraction layer to deviate from its ideal value. [66] (iii) The lack of a matching structure at the base of each unit cell results in standing waves forming from reflected and incident waves. Moreover, refraction occurs when waves pass from silicon to an air slot. These aspects have been omitted in the computation for simplicity. (iv) The diffraction layer is not entirely enclosed, which allows the wave to propagate around, introducing noise.
6.2 Discussion
모모When developing the integrated neural network architecture in the optical system, it is essential to account for various factors, including classification accuracy on the test set, accumulated errors, and power consumption.  Regarding power consumption, the integrated diffractive deep neural network operates entirely optically, performing computations on optical signals without needing additional energy input, aside from the energy needed for signal input, once fabricated on an SOI substrate. As a result, the power consumption of the fixed ID^2NN relies only on the external optical source that supplies the input signal(loading process). The main losses in the ID^2NN include propagation loss and transmission loss of the diffraction layer. In our design, computed by Lumerical FDTD, the loss per diffraction layer is less than  0.46\ dB at the wavelength of 1.55?m. In our design, one neuron is mapped to one slot. However, in an effort to suppress interference, we can use multiple slots to represent one neuron (i.e. two slots or three slots for one neuron).[68, 69] 
모모For the scale of our proposed 5-layer ID^2NN, the width is 0.5\ ?m뫄300 = 150 ?m, and the footprint approximately 150?m뫄,80+(5+1)뫄300.?m=282000?,m-2., where 80?m includes the length of the narrow input waveguide and the length of the tapers in the output plane. The total  footprint of our  5-layer ID^2NN is smaller than the previously presented MZI-based photonic neural network.[25, 67]
모모The whole system of  ID^2NN contains 1500 trainable neurons, corresponding to 300 slots in 5 diffractive layers (or meta lines) and has an MNIST classification accuracy of 91.6% and a Fashion MNIST classification accuracy of 74.71%. The accuracy of our proposed 5-layer ID^2NN on MNIST is comparable to the state-of-the-art (90% to 99%). However, the accuracy of Fashion MNIST is below most machine learning methods(>80%), which could be due to over-downsampled, resulting in the loss of distinguishable features. For FashionMNIST, directly loading the data without downsampling could potentially improve the accuracy but comes at the cost of enlarging system scale(N\geq784), which is very challenging[70]. Optical non-linear activation may improve the system's performance, but this thesis does not discuss nor utilise it. This is because achieving neuron thresholding effects in photonic cascadability presents a considerable challenge.[71, 72]
모모Finally, although our ID^2NN architecture has the advantages such as on-chip miniaturization (no alignment required between integrated diffraction layers due to the existing advanced lithography techniques), whole-passive structure, light-speed processing, reduced power consumption and easy scalability to large numbers of neurons, and it does have some limitations. The accumulated approximation error restricts the parallelity of the ID^2NN, meaning that neurons per layer(parallel processing unit) should be kept within a suitable number and degrades actual performance as the number of diffraction layers increases. Therefore, it remains essential to refine the model to give better approximation and search for to new physical method in neuron value mapping to further accurate the phase shift produced by a single unit cell.
Conclusion and Future Work
모모In conclusion, we have presented the design framework for a fully passive, all-optical ID^2NN architecture based on SOI, where pre-trained neuron values are associated with phase delays in physical structures and the desired phase delays is produced by varying the length of the etched slots. Each neuron value is approximated by one slot. The system structural parameters, which include the neuron feature size, number of neurons per layer and the distance between two adjacent integrated diffraction layers, satisfied the fully connected topology, ensuring sufficient information transfer between layers. The photonic integrated ID^2NN architecture can process complex information at the speed of light with low power consumption due to its inherent nature. Additionally, the chip manufacturing process is compatible with CMOS technology, allowing for large-scale, cost-effective production. Furthermore, in comparison  to other on-chip optical neural networks, our  proposed ID^2NN  in this thesis offers advantages such as simple structure, high integrability and ease in scalability, among others. This deep learning framework we have designed for  ID^2NN may also pave the way for other applications, such as speech recognition, data mining, object classification, and more. Furthermore, in the era beyond Moore's law, it is one of the most potential solutions for breaking the von Neumann bottleneck and surmounting the technical obstacles of conventional electronic artificial neural networks.
모모However, there are still several directions or issues that have not been fully explored and need effort in the future: (i) Although optical diffraction neural networks can execute various complex tasks at the speed of light, the learning and training still follow the artificial neural network algorithm framework and are implemented via computer. Avoiding the computer side (computer-free) and constructing a truly all-optical learning framework has significant implications for the development of diffractive deep neural networks. (ii) In the development of real-world systems, one of the essential future research directions may be to compensate for and eliminate errors in modelling and physical mapping to maintain high numerical classification accuracy.
Appendix
모모In the appendix, we provide our code to train and implement the integrated diffractive deep neural network, which is available at  https://github.com/0ce38a2b/Integrated-Diffractive-Deep-Neural-Network.
Reference
[1] 	Deep learning | nature [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://www.nature.com/articles/nature14539
[2] 	Helping robots see the big picture | Science [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://www.science.org/doi/full/10.1126/science.346.6206.186
[3] 	Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups | IEEE Journals & Magazine | IEEE Xplore [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://ieeexplore.ieee.org/document/6296526
[4] 	A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots | IEEE Journals & Magazine | IEEE Xplore [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://ieeexplore.ieee.org/document/7358076
[5] 	CANZIANI, Alfredo, Adam PASZKE a Eugenio CULURCIELLO. An Analysis of Deep Neural Network Models for Practical Applications [online]. B.m.: arXiv. 14.?duben?2017 [vid.?2022-12-21]. Dostupn뺝 z:?doi:10.48550/arXiv.1605.07678. arXiv:1605.07678 [cs]
[6] 	Tunable lifetime nanocrystals | Nature Photonics [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://www.nature.com/articles/nphoton.2013.353
[7] 	YAN, Tao, Jiamin WU, Tiankuang ZHOU, Hao XIE, Feng XU, Jingtao FAN, Lu FANG, Xing LIN a Qionghai DAI. Fourier-space Diffractive Deep Neural Network. Physical Review Letters [online]. 2019, 123(2), 023901. Dostupn뺝 z:?doi:10.1103/PhysRevLett.123.023901
[8] 	WALDROP, M. Mitchell. The chips are down for Moore's law. Nature News [online]. 2016, 530(7589), 144. Dostupn뺝 z:?doi:10.1038/530144a
[9] 	STROEV, Nikita a Natalia G. BERLOFF. Renaissance of Analogue Optical Computing [online]. B.m.: arXiv. 27.?leden?2023 [vid.?2023-04-06]. Dostupn뺝 z:?doi:10.48550/arXiv.2301.11760. arXiv:2301.11760 [physics, physics:quant-ph]
[10] 	Artificial neural networks: a tutorial | IEEE Journals & Magazine | IEEE Xplore [online]. [vid.?2023-04-06]. Dostupn뺝 z:?https://ieeexplore.ieee.org/document/485891
[11] 	MCCULLOCH, Warren S. a Walter PITTS. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics [online]. 1943, 5(4), 115C133. ISSN?1522-9602. Dostupn뺝 z:?doi:10.1007/BF02478259
[12] 	EFNUSHEVA, Danijela, Ana CHOLAKOSKA a Aristotel TENTOV. A SURVEY OF DIFFERENT APPROACHES FOR OVERCOMING THE PROCESSOR-MEMORY BOTTLENECK. International Journal of Information Technology and Computer Science [online]. 2017, 151. Dostupn뺝 z:?doi:10.5121/ijcsit.2017.9214
[13] 	Beyond von Neumann. Nature Nanotechnology [online]. 2020, 15(7), 507C507. ISSN?1748-3395. Dostupn뺝 z:?doi:10.1038/s41565-020-0738-x
[14] 	Artificial neural networks enabled by nanophotonics | Light: Science & Applications [online]. [vid.?2023-04-06]. Dostupn뺝 z:?https://www.nature.com/articles/s41377-019-0151-0
[15] 	SWEET, J.N. Integrated test chips improve IC assembly. IEEE Circuits and Devices Magazine [online]. 1990, 6(5), 39C45. ISSN?1558-1888. Dostupn뺝 z:?doi:10.1109/101.59444
[16] 	SHULAKER, Max M., Gage HILLS, Rebecca S. PARK, Roger T. HOWE, Krishna SARASWAT, H.-S. Philip WONG a Subhasish MITRA. Three-dimensional integration of nanotechnologies for computing and data storage on a single chip. Nature [online]. 2017, 547(7661), 74C78. ISSN?1476-4687. Dostupn뺝 z:?doi:10.1038/nature22994
[17] 	PATTI, R.S. Three-Dimensional Integrated Circuits and the Future of System-on-Chip Designs. Proceedings of the IEEE [online]. 2006, 94(6), 1214C1224. ISSN?1558-2256. Dostupn뺝 z:?doi:10.1109/JPROC.2006.873612
[18] 	Phys. Rev. Applied 11, 014063 (2019) - Photonic In-Memory Computing Primitive for Spiking Neural Networks Using Phase-Change Materials [online]. [vid.?2023-04-06]. Dostupn뺝 z:?https://journals.aps.org/prapplied/abstract/10.1103/PhysRevApplied.11.014063
[19] 	ELEFTHERIOU, E., M. Le GALLO, S. R. NANDAKUMAR, C. PIVETEAU, I. BOYBAT, V. JOSHI, R. KHADDAM-ALJAMEH, M. DAZZI, I. GIANNOPOULOS, G. KARUNARATNE, B. KERSTING, M. STANISAVLJEVIC, V. P. JONNALAGADDA, N. IOANNOU, K. KOURTIS, P. A. FRANCESE a A. SEBASTIAN. Deep learning acceleration based on in-memory computing. IBM Journal of Research and Development [online]. 2019, 63(6), 7:1-7:16. ISSN?0018-8646. Dostupn뺝 z:?doi:10.1147/JRD.2019.2947008
[20] 	HIGHLANDER, Tyler a Andres RODRIGUEZ. Very Efficient Training of Convolutional Neural Networks using Fast Fourier Transform and Overlap-and-Add [online]. B.m.: arXiv. 25.?leden?2016 [vid.?2023-04-06]. Dostupn뺝 z:?doi:10.48550/arXiv.1601.06815. arXiv:1601.06815 [cs]
[21] 	YOUSSEF, Ahmed. Algorithmic Techniques towards Efficient Quantization of Deep Neural Networks [online]. B.m., 2020 [vid.?2023-04-06]. UC San Diego. Dostupn뺝 z:?https://escholarship.org/uc/item/1b84q7vf
[22] 	MOORE, Gordon E. Cramming More Components onto Integrated Circuits. PROCEEDINGS OF THE IEEE. 1998, 86(1). 
[23] 	HILL, Mark D., Norman P. JOUPPI a Gurindar S. SOHI, ed. Readings in Computer Architecture. 1st edition. San Francisco: Morgan Kaufmann, 1999. ISBN?978-1-55860-539-8. 
[24] 	SOLLI, Daniel R. a Bahram JALALI. Analog optical computing. Nature Photonics [online]. 2015, 9(11), 704C706. ISSN?1749-4893. Dostupn뺝 z:?doi:10.1038/nphoton.2015.208
[25] 	SHEN, Yichen, Nicholas C. HARRIS, Scott SKIRLO, Mihika PRABHU, Tom BAEHR-JONES, Michael HOCHBERG, Xin SUN, Shijie ZHAO, Hugo LAROCHELLE, Dirk ENGLUND a Marin SOLJA?I?. Deep learning with coherent nanophotonic circuits. Nature Photonics [online]. 2017, 11(7), 441C446. ISSN?1749-4893. Dostupn뺝 z:?doi:10.1038/nphoton.2017.93
[26] 	PSALTIS, Demetri, David BRADY, Xiang-Guang GU a Steven LIN. Holography in artificial neural networks. Nature [online]. 1990, 343(6256), 325C330. ISSN?1476-4687. Dostupn뺝 z:?doi:10.1038/343325a0
[27] 	All-optical machine learning using diffractive deep neural networks | Science [online]. [vid.?2022-11-25]. Dostupn뺝 z:?https://www.science.org/doi/10.1126/science.aat8084
[28] 	LIU, Jia-ming. Photonic Devices [online]. B.m.: Cambridge University Press, 2005. ISBN?978-0-511-61425-5. Dostupn뺝 z:?https://doi.org/10.1017/CBO9780511614255
[29] 	Saleh, A. and Malvin Carl Teich. FUNDAMENTALSOF PHOTONICS. nedatov뺙no. ISBN?978-1-119-50687-4. 
[30] 	C. R. POLLOCK. Fundamentals of Optoelectronics. B.m.: Richard d Irwin, nedatov뺙no. ISBN?0-256-10104-3. 
[31] 	COLDREN, Larry A. Diode Lasers and Photonic Integrated Circuits. In:?Optical Engineering [online]. 1997, s.?616 [vid.?2022-12-21]. ISSN?0091-3286. Dostupn뺝 z:?doi:10.1117/1.601191
[32] 	KUSKO, M., D. COJOC, D. APOSTOL, R. MULLER, E. MANEA a C. PODARU. Design and fabrication of diffractive optical elements. In:?2003 International Semiconductor Conference. CAS 2003 Proceedings (IEEE Cat. No.03TH8676): 2003 International Semiconductor Conference. CAS 2003 Proceedings (IEEE Cat. No.03TH8676) [online]. 2003, s.?167-170 Vol. 1. Dostupn뺝 z:?doi:10.1109/SMICND.2003.1251370
[33] 	NEFF, J.A., R.A. ATHALE a S.H. LEE. Two-dimensional spatial light modulators: a tutorial. Proceedings of the IEEE [online]. 1990, 78(5), 826C855. ISSN?1558-2256. Dostupn뺝 z:?doi:10.1109/5.53402
[34] 	YANG, Huanhuan, Xiangyu CAO, Fan YANG, Jun GAO, Shenheng XU, Maokun LI, Xibi CHEN, Yi ZHAO, Yuejun ZHENG a Sijia LI. A programmable metasurface with dynamic polarization, scattering and focusing control. Scientific Reports [online]. 2016, 6(1), 35692. ISSN?2045-2322. Dostupn뺝 z:?doi:10.1038/srep35692
[35] 	BARLOW, H. B. Unsupervised learning. Neural computation [online]. 1989, 1, 295C311. ISSN?1530-888X. Dostupn뺝 z:?doi:10.1162/neco.1989.1.3.295
[36] 	BUENO, J., S. MAKTOOBI, L. FROEHLY, I. FISCHER, M. JACQUOT, L. LARGER a D. BRUNNER. Reinforcement learning in a large-scale photonic recurrent neural network. Optica [online]. 2018, 5(6), 756C760. ISSN?2334-2536. Dostupn뺝 z:?doi:10.1364/OPTICA.5.000756
[37] 	BORN, Max. Electromagnetic theory of propagation, interference and diffraction of light. nedatov뺙no. 
[38] 	PASZKE, Adam, Sam GROSS, Francisco MASSA, Adam LERER, James BRADBURY, Gregory CHANAN, Trevor KILLEEN, Zeming LIN, Natalia GIMELSHEIN, Luca ANTIGA, Alban DESMAISON, Andreas KOPF, Edward YANG, Zachary DEVITO, Martin RAISON, Alykhan TEJANI, Sasank CHILAMKURTHY, Benoit STEINER, Lu FANG, Junjie BAI, Soumith CHINTALA, H. WALLACH, H. LAROCHELLE, A. BEYGELZIMER, F. D몶ALCH?-BUC, E. FOX a R. GARNETT. PyTorch: An Imperative Style, High-Performance Deep Learning Library [online]. C++. B.m.: Curran Associates, Inc. 2019 [vid.?2023-04-06]. Dostupn뺝 z:?http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf
[39] 	ABADI, Mart뺡n, Ashish AGARWAL, Paul BARHAM, Eugene BREVDO, Zhifeng CHEN, Craig CITRO, Greg S. CORRADO, Andy DAVIS, Jeffrey DEAN, Matthieu DEVIN, Sanjay GHEMAWAT, Ian GOODFELLOW, Andrew HARP, Geoffrey IRVING, Michael ISARD, Rafal JOZEFOWICZ, Yangqing JIA, Lukasz KAISER, Manjunath KUDLUR, Josh LEVENBERG, Dan MAN?, Mike SCHUSTER, Rajat MONGA, Sherry MOORE, Derek MURRAY, Chris OLAH, Jonathon SHLENS, Benoit STEINER, Ilya SUTSKEVER, Kunal TALWAR, Paul TUCKER, Vincent VANHOUCKE, Vijay VASUDEVAN, Fernanda VI?GAS, Oriol VINYALS, Pete WARDEN, Martin WATTENBERG, Martin WICKE, Yuan YU a Xiaoqiang ZHENG. TensorFlow, Large-scale machine learning on heterogeneous systems [online]. C++. listopad?2015 [vid.?2023-04-06]. Dostupn뺝 z:?doi:10.5281/zenodo.4724125
[40] 	A programmable diffractive deep neural network based on a digital-coding metasurface array | Nature Electronics [online]. [vid.?2022-12-15]. Dostupn뺝 z:?https://www.nature.com/articles/s41928-022-00719-9
[41] 	Performing optical logic operations by a diffractive neural network | Light: Science & Applications [online]. [vid.?2022-12-15]. Dostupn뺝 z:?https://www.nature.com/articles/s41377-020-0303-2
[42] 	Spectrally encoded single-pixel machine vision using diffractive networks | Science Advances [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://www.science.org/doi/10.1126/sciadv.abd7690
[43] 	LI, Jingxi, Deniz MENGU, Yi LUO, Yair RIVENSON a Aydogan OZCAN. Class-specific Differential Detection in Diffractive Optical Neural Networks Improves Inference Accuracy. Advanced Photonics [online]. 2019, 1(04), 1. ISSN?2577-5421. Dostupn뺝 z:?doi:10.1117/1.AP.1.4.046001
[44] 	LU, Lidan, Zhoumo ZENG, Lianqing ZHU, Qiankun ZHANG, Bofei ZHU, Qifeng YAO, Mingxing YU, Haisha NIU, Mingli DONG a Guoshun ZHONG. Miniaturized Diffraction Grating Design and Processing for Deep Neural Network. IEEE Photonics Technology Letters [online]. 2019, 31(24), 1952C1955. ISSN?1041-1135, 1941-0174. Dostupn뺝 z:?doi:10.1109/LPT.2019.2948626
[45] 	SHI, Jiashuo. A Diffractive Neural Network with Weight-Noise-Injection Training [online]. B.m.: arXiv. 20.??erven?2020 [vid.?2022-12-21]. Dostupn뺝 z:?doi:10.48550/arXiv.2006.04462. arXiv:2006.04462 [cs, eess]
[46] 	Misalignment resilient diffractive optical networks [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://www.degruyter.com/document/doi/10.1515/nanoph-2020-0291/html
[47] 	MENGU, Deniz, Yair RIVENSON a Aydogan OZCAN. Scale-, shift- and rotation-invariant diffractive optical networks. ACS Photonics [online]. 2021, 8(1), 324C334. ISSN?2330-4022, 2330-4022. Dostupn뺝 z:?doi:10.1021/acsphotonics.0c01583
[48] 	LABORDE, Victor, J뺝r?me LOICQ, Juriy HASTANIN a Serge HABRAKEN. Multi-layer diffractive optical element material selection method based on transmission, total internal reflection, and thickness. Applied Optics [online]. 2022, 61(25), 7415C7423. ISSN?2155-3165. Dostupn뺝 z:?doi:10.1364/AO.465999
[49] 	PSALTIS, Demetri. Coherent optical information systems. Science (New York, N.Y.) [online]. 2002, 298(5597), 1359C1363. ISSN?1095-9203. Dostupn뺝 z:?doi:10.1126/science.1078823
[50] 	LUO, Xuhao, Yueqiang HU, Xiangnian OU, Xin LI, Jiajie LAI, Na LIU, Xinbin CHENG, Anlian PAN a Huigao DUAN. Metasurface-enabled on-chip multiplexed diffractive neural networks in the visible. Light: Science & Applications [online]. 2022, 11(1), 158. ISSN?2047-7538. Dostupn뺝 z:?doi:10.1038/s41377-022-00844-2
[51] 	Goodman, J.W. (1996). Introduction to Fourier Optics. B.m.: McGraw-Hill Science, Engineering & Mathematics, nedatov뺙no. 
[52] 	Vasudevan Lakshminarayanan, Hassen Ghalila, Ammar, A. and L. Srinivasa Varadharajan (2018). Understanding Optics with Python. B.m.: CRC Press, nedatov뺙no. 
[53] 	David George Voelz (2010). Computational Fourier optics?: a MATLAB tutorial. B.m.: Bellingham, Wash.: Spie Press, nedatov뺙no. 
[54] 	BASSEY, Joshua, Lijun QIAN a Xianfang LI. A Survey of Complex-Valued Neural Networks [online]. B.m.: arXiv. 28.?leden?2021 [vid.?2022-12-03]. Dostupn뺝 z:?doi:10.48550/arXiv.2101.12249. arXiv:2101.12249 [cs, stat]
[55] 	MEHRABKHANI, Soheil a Thomas SCHNEIDER. Is the Rayleigh-Sommerfeld diffraction always an exact reference for high speed diffraction algorithms? Optics Express [online]. 2017, 25(24), 30229. ISSN?1094-4087. Dostupn뺝 z:?doi:10.1364/OE.25.030229
[56] 	BUITRAGO-DUQUE, Carlos a Jorge GARCIA-SUCERQUIA. Non-approximated RayleighCSommerfeld diffraction integral: advantages and disadvantages in the propagation of complex wave fields. Applied Optics [online]. 2019, 58(34), G11CG18. ISSN?2155-3165. Dostupn뺝 z:?doi:10.1364/AO.58.000G11
[57] 	Introduction to artificial neural networks | IEEE Conference Publication | IEEE Xplore [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://ieeexplore.ieee.org/document/483329
[58] 	A Hybrid Training Algorithm for Feedforward Neural Networks | SpringerLink [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://link.springer.com/article/10.1007/s11063-006-9013-x
[59] 	CHEN, Hang, Jianan FENG, Minwei JIANG, Yiqun WANG, Jie LIN, Jiubin TAN a Peng JIN. Diffractive Deep Neural Networks at Visible Wavelengths. Engineering [online]. 2021, 7(10), 1483C1491. ISSN?2095-8099. Dostupn뺝 z:?doi:10.1016/j.eng.2020.07.032
[60] 	LI DENG. The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]. IEEE Signal Processing Magazine [online]. 2012, 29(6), 141C142. ISSN?1053-5888. Dostupn뺝 z:?doi:10.1109/MSP.2012.2211477
[61] 	XIAO, Han, Kashif RASUL a Roland VOLLGRAF. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms [online]. B.m.: arXiv. 15.?z뺙?뺡?2017 [vid.?2023-04-07]. Dostupn뺝 z:?doi:10.48550/arXiv.1708.07747. arXiv:1708.07747 [cs, stat]
[62] 	MOSS, David. Photonic multiplexing architectures for optical neuromorphic networks [online]. 2022 [vid.?2022-12-21]. Dostupn뺝 z:?https://hal.archives-ouvertes.fr/hal-03764240
[63] 	MARMOLIN, Hans. Subjective MSE measures. IEEE Transactions on Systems, Man, & Cybernetics [online]. 1986, SMC-16, 486C489. ISSN?0018-9472. Dostupn뺝 z:?doi:10.1109/TSMC.1986.4308985
[64] 	CSIRO Research Publications Repository - On the pairing of the softmax activation and cross-entropy penalty functions and the derivation of the softmax activiation functions [online]. [vid.?2022-12-21]. Dostupn뺝 z:?https://publications.csiro.au/rpr/pub?list=BRO&pid=procite:bf1f60dc-ea12-49a7-a14d-79b1419a475e
[65] 	WANG, Zi, Tiantian LI, Anishkumar SOMAN, Dun MAO, Thomas KANANEN a Tingyi GU. On-chip wavefront shaping with dielectric metasurface. Nature Communications [online]. 2019, 10(1), 3547. ISSN?2041-1723. Dostupn뺝 z:?doi:10.1038/s41467-019-11578-y
[66] 	BACKER, Adam S. Computational inverse design for cascaded systems of metasurface optics. Optics Express [online]. 2019, 27(21), 30308C30331. ISSN?1094-4087. Dostupn뺝 z:?doi:10.1364/OE.27.030308
[67] 	HUGHES, Tyler W., Momchil MINKOV, Yu SHI a Shanhui FAN. Training of photonic neural networks through in situ backpropagation and gradient measurement. Optica [online]. 2018, 5(7), 864C871. ISSN?2334-2536. Dostupn뺝 z:?doi:10.1364/OPTICA.5.000864
[68] 	FU, Tingzhao, Yubin ZANG, Honghao HUANG, Zhenmin DU, Chengyang HU, Minghua CHEN, Sigang YANG a Hongwei CHEN. On-chip photonic diffractive optical neural network based on a spatial domain electromagnetic propagation model. Optics Express [online]. 2021, 29(20), 31924C31940. ISSN?1094-4087. Dostupn뺝 z:?doi:10.1364/OE.435183
[69] 	WANG, Zi, Lorry CHANG, Feifan WANG, Tiantian LI a Tingyi GU. Integrated photonic metasystem for image classifications at telecommunication wavelength. Nature Communications [online]. 2022, 13(1), 2131. ISSN?2041-1723. Dostupn뺝 z:?doi:10.1038/s41467-022-29856-7
[70] 	HAMERLY, Ryan, Liane BERNSTEIN, Alexander SLUDDS, Marin SOLJA?I? a Dirk ENGLUND. Large-Scale Optical Neural Networks based on Photoelectric Multiplication. Physical Review X [online]. 2019, 9(2), 021032. ISSN?2160-3308. Dostupn뺝 z:?doi:10.1103/PhysRevX.9.021032
[71] 	WILLIAMSON, Ian A. D., Tyler W. HUGHES, Momchil MINKOV, Ben BARTLETT, Sunil PAI a Shanhui FAN. Reprogrammable Electro-Optic Nonlinear Activation Functions for Optical Neural Networks. IEEE Journal of Selected Topics in Quantum Electronics [online]. 2020, 26(1), 1C12. ISSN?1558-4542. Dostupn뺝 z:?doi:10.1109/JSTQE.2019.2930455
[72] 	ZUO, Ying, Bohan LI, Yujun ZHAO, Yue JIANG, You-Chiuan CHEN, Peng CHEN, Gyu-Boong JO, Junwei LIU a Shengwang DU. All-optical neural network with nonlinear activation functions. Optica [online]. 2019, 6(9), 1132C1137. ISSN?2334-2536. Dostupn뺝 z:?doi:10.1364/OPTICA.6.001132


2
Huayi Sheng, 896039

